\chapter{}

\topic{Modules over principal domains}

\begin{theorem}
\label{thm:rango}
Let $R$ be a principal domain. If $F$ is a finitely generated free module and 
$N$ is a submodule of $F$, then $N$ is free and 
$\rank(N)\leq\rank(F)$. 
\end{theorem}

\begin{proof}
	We proceed by induction on $n=\rank(F)$. Si $n=1$, entonces
	$F\simeq\prescript{}{R}R$ 
	and the submodules of $F$ are exactly the left ideals of $R$. In particular,
	$N=(r)$ for some $r\in R$. If $r=0$, then $N=\{0\}$ and the result holds. If $r\ne 0$, then 
	$\{r\}$ is basis of $N$ and the result holds.
	
	Assume now that the result holds for all free module of rank $<n$. 
	Let $\{f_1,\dots,f_n\}$ be basis of $F$ and $F_n=(f_1,\dots,f_{n-1})$. By the inductive hypothesis, 
	$U=N\cap F_n$ is free of rank $\leq n-1$. Let 
	$\{n_1,\dots,n_k\}$ be a basis of $U$ (by convention, if $U=\{0\}$, then $k=0$). If 
	$f\in F$, there exist unique $r_1,\dots,r_n\in R$ such that  
	\[
	f=\sum_{i=1}^n r_i\cdot f_i.
	\]
	There exists a well-defined homomorphism 
	\[
	\varphi\colon F\to R,
	\quad
	\sum_{i=1}^nr_i\cdot f_i\mapsto r_n.
	\] 
	If $\varphi(N)=\{0\}$, then $N\subseteq (f_1,\dots,f_{n-1})$ and thus $N=U$. 
	If $\varphi(N)\ne\{0\}$, then $\varphi(N)$ is an ideal of 
	$R$, say $\varphi(N)=(x)$ for some $x\in R\setminus\{0\}$. Let $n_{k+1}\in N$ 
	be such that $\varphi(n_{k+1})=x$. 
    We claim that $\{n_1,\dots,n_k,n_{k+1}\}$ is basis of $N$. 
	If $n\in N$, then $\varphi(n)=rx$ 
	for some $r\in R$. Thus $n-r\cdot n_{k+1}\in N\cap\ker\varphi=N\cap F_n=U$, as  
	$\varphi(n-r\cdot n_{k+1})=0$. In particular, 
	\[
	n-r\cdot n_{k+1}\in (n_1,\dots,n_k)\implies  
	n\in (n_1,\dots,n_k,n_{k+1}).
	\]
	We claim that 
	$\{n_1,\dots,n_k,n_{k+1}\}$ is linearly independent. If 
	\[
	0=\sum_{i=1}^{k+1}r_i\cdot n_i,
	\]
	for some $r_1,\dots,r_{k+1}\in R$, then, since 
	$\varphi(n_i)=0$ for all $i\in\{1,\dots,k\}$,
	\[
	0=\varphi(r_{k+1}\cdot n_{k+1})=r_{k+1}x.
	\]
	This implies that $r_{k+1}=0$. Thus $\sum_{i=1}^kr_i\cdot n_i=0$. Since
	$\{n_1,\dots,n_k\}$ is basis of $U$, we conclude that 
	$r_1=\dots=r_k=0$. 
\end{proof}

The previous theorem also holds for infinite bases. However, 
the proof requires the use of Zorn's lemma. 
% reference?
	
% \begin{corollary}
% Sea $R$ un dominio de ideales principales. Si $M$ es proyectivo y finitamente generado, 
% entonces $M$ es libre.
% \end{corollary}

% \begin{proof}
% Supongamos que $M=(m_1,\dots,m_k)$. Sabemos que $M$ es sumando directo de un libre $F$. Fijemos una base de $F$ y sea 
% $X=\{f_1,f_2,\dots\}$ un subconjunto finito de esa base de $F$ tal que
% \[
% m_j=\sum_{i=1}^{n_j}r_{ij}\cdot f_i
% \]
% para ciertos $r_{ij}\in R$ y ciertos $n_1\dots,n_k\in\N$. 
% Por construcción, $X$ es linealmente indepdendiente y $M=(X)$. 
% \end{proof}

% El corolario anterior vale también para módulos arbitrarios. La demostración puede
% consultarse por ejemplo en~\cite[I, Theorem 5.1]{MR1438546}.

\begin{corollary}
Let $R$ be a principal domain. If $M$ is finitely generated and $N$ 
is a submodule of $M$, then $N$ is finitely generated.   
\end{corollary}

\begin{proof}
There exists a free module $F$ of finite rank and a surjective homomorphism
$\varphi\colon F\to M$. Sinc $N_1=\varphi^{-1}(N)$ is a submodule of $F$, 
the previous theorem implies that  
$\rank(N_1)\leq\rank F$. If $\{x_1,\dots,x_k\}$ is basis of $N_1$, then, since $\varphi$ 
is a surjective homomorphism, 
$\{\varphi(x_1),\dots,\varphi(x_k)\}$ is a generating set of 
$\varphi(N_1)=\varphi(\varphi^{-1}(N))=N$. In particular, $\rank(N)\leq k=\rank(N_1)\leq\rank(F)$. 
\end{proof}

Some exercises:

\begin{exercise}
\label{xca:rank}
    Let $R$ be a principal domain and 
    let $M$ be a free module. If $S$ is a submodule of $M$ such that
    $M/S$ is free, then $M\simeq S\oplus (M/S)$. If, moreover,  
	$S$ is free, then 
	\[
	\rank(M)=\rank(S)+\rank(M/S).
	\] 
\end{exercise}

\begin{exercise}
\label{xca:n_elements}
    Let $R$ be a principal domain. 
    If $M$ is a free module of rank $n$, then
    every linearly independent subset of $M$ 
    contains at most $n$ elements. 
\end{exercise}

\begin{exercise}
    Let $R$ be a principal domain. 
    and $M$ and $N$ be free modules. Prove that 
    $M\simeq N$ if and only if $\rank(M)=\rank(N)$. 	
\end{exercise}

\begin{exercise}
\label{xca:base}
    Let $R$ be a principal domain. 
    If $M$ is a free module of finite rank $n$ and $\{s_1,\dots,s_n\}$ 
    is a generating set, then $\{s_1,\dots,s_n\}$ is a basis of $M$.
\end{exercise}

\index{Annihilator!of a module}
\index{Annihilator!of an element}
If $M$ is a module, the \textbf{annihilator} of $M$ 
is defined as 
\[
\Ann(M)=\{r\in R:r\cdot m=0\text{ for all $m\in M$}\}.
\] 
Si $m\in M$ se define 
\[
\Ann(m)=\{r\in R:r\cdot m=0\}.
\]  
Note that $\Ann(M)=\cap_{m\in M}\Ann(m)$. 
It is an exercise to show that both 
$\Ann(M)$ and $\Ann(m)$ are ideals of $R$. 
If $r\in R$, the annihilator of $r$ in $M$ 
is defined as 
\[
\Ann_M(r)=\{m\in M:r\cdot m=0\}.
\] 
It is an exercise to show that $\Ann_M(r)$ is a submodule of 
$M$. 

\begin{exercise}
Let $M$ be a module. Let $m\in M$ and $r\in R$ be such that $\Ann(m)=(r)$.
Let 
$p\in R$ be an irreducible element. 
\begin{enumerate}
\item If $p$ divides $r$, then $(m)/p\cdot (m)\simeq R/(p)$.
\item If $p$ does not divide $r$, then $p\cdot (m)=(m)$.
\end{enumerate}
\end{exercise}

% Demostremos la primera afirmación. Sea $\varphi\colon R\to (m)$, $s\mapsto s\cdot m$, y 
% sea $f=\pi\circ \varphi\colon R\to (m)/p\cdot (m)$, donde $\pi\colon (m)\to (m)/p\cdot (m)$ es 
% el epimorfismo canónico. Veamos que $\ker f=(p)$. Trivialmente vale 
% que $\ker f\supseteq (p)$. Por otro lado, si $s\in R$ es tal que
% s\cdot m\in p\cdot (m)$, entonces, como $r=pt$ para algún $t\in R$, $s\cdot m=t\cdot (p\cdot m)$.
% Como $f$ es epimorfismo por ser composición
% de epimorfismos, se tiene que $R/(p)\simeq (m)/p\cdot (m)$.  

% Demostremos ahora la segunda afirmación. Como $p$ y $r$ son coprimos, existen 
% $a,b\in R$ tales que $ap+br=1$. Como $r\cdot \m=0$ pues $\Ann(m)=(r)$, 
% $m=1\cdot m=(ap+br)\cdot m=p\cdot (a\cdot m)\in p\cdot (m)$.  

\index{Torsion!of a module}
\index{Torsion-free module}
\index{Torsion module}
The \textbf{torsion} of a module $M$ 
is defined as the subset 
\[
T(M)=\{m\in M:r\cdot m=0\text{ for some $r\in R$}\}.
\]
It is an exercise to show that $T(M)$ is a submodule of $M$. 
A module $M$ 
\textbf{is torsion-free} if $T(M)=\{0\}$ and it is 
a \textbf{torsion} module if $T(M)=M$.   

\begin{exercise}
If $M\simeq N$, then $T(M)\simeq T(N)$.
\end{exercise}

\begin{exercise}
Prove that $T(\oplus_{i\in I}M_i)\simeq \oplus_{i\in I}T(M_i)$.
\end{exercise}

\begin{exercise}
\label{xca:free}
    Let $R$ be a principal domain and $M$ be a module. Prove that
    if $M$ is finitely generated and $S\subseteq M$ is a free submodule such that
    $M/S$ is torsion-free, then $M$ is free.
\end{exercise}

Clearly, $T(\Z/n)=\Z/n$ and $T(\Q)=\{0\}$.

\begin{example}
    Let $R$ be a ring, viewed as a module with left multiplication. 
    Then $T(R)=\{r\in R:rs=0\text{ for some $s\in R$}\}$.
\end{example}

\begin{example}
    Let $M$ be the module (over $\Z$) of
    integer sequences, that is $M=\Z^I$, where 
    $I=\{1,2,3,\dots\}$. Then $T(M)=\{0\}$. 
\end{example}

\begin{example}
If $V$ is a finite-dimensional vector space and $T\colon V\to V$ 
is a linear transformation, $V$ is a module (over $K[X]$) 
with 
\[
\left(\sum_{i=0}^n a_iX^i\right)\cdot v=\sum_{i=0}^n a_iT^i(v).
\]

We claim that 
$V$ is a torsion module, that is $V=T(V)$. Let $n=\dim V$. If $v\in V$, 
then $\{v,T(v),\dots,T^n(v)\}$ is linearly dependent, as it has 
$n+1$ elements. In particular, there exist $a_0,\dots,a_n\in K$ not all zero such that
\[
0=\sum_{i=0}^n a_iT^i(v)=\left(\sum_{i=0}^n a_iX^i\right)\cdot v.
\]
Thus $v\in T(V)$. 
\end{example}

\begin{theorem}
Sea $R$ un dominio de ideales principales  
y sea $M$ finitamente generado. Si $T(M)=\{0\}$, entonces $M$ es libre. 
\end{theorem}

\begin{proof}
Sin perder generalidad podemos suponer que $M$ es no nulo. Supongamos además que $M=(X)$, donde $X$ es un conjunto 
finito de generadores. Si $x\in X$, entonces $r\cdot x=0\Longleftrightarrow r=0$, pues $T(M)=\{0\}$. Sea $S=\{x_1,\dots,x_k\}\subseteq X$ 
maximal con respecto a la siguiente propiedad:
\[
r_1\cdot x_1+\cdots+r_k\cdot x_k=0\text{ para $r_1,\dots,r_k\in R$}\implies r_1=\cdots=r_k=0.
\]	
Sea $F=(S)$ el módulo libre con base en el conjunto $S$. Si $X=S$, no hay nada para demostrar. 
Si $y\in X\setminus S$, entonces
existen $r_y,r_1,\dots,r_k\in R$ no todos cero tales que
\[
r_y\cdot y+\sum_{i=1}^k r_i\cdot x_i=0.
\]
Como entonces $r_y\cdot y=-\sum_{i=1}^k r_i\cdot x_i\in F$, se concluye que $r_y\ne 0$, pues si 
$r_y=0$ entonces $r_1=\cdots=r_k=0$. Como $X$ es finito, 
\[
r=\prod_{y\in X\setminus S}r_y
\]
está bien definido pues $R$ es conmutativo y es tal que $r\cdot X\subseteq F$. Si $f\colon M\to M$, $x\mapsto r\cdot x$, entonces
$f$ es un morfismo tal que $f(M)=r\cdot M$. Como $T(M)=\{0\}$, entonces $\ker f=\{0\}$. Luego
\[
r\cdot M=f(M)\simeq M
\]
y en consecuencia $M$ es libre. 
\end{proof}

%\begin{theorem}
%Si $M$ es libre y finitamente generado y $N$ es un submódulo de $M$, entonces $N$ es también libre.
%\end{theorem}

%\begin{proof}
%Sea $\{m_1,\dots,m_k\}$ una base de $M$. Procederemos por inducción en $k$. Para cada $j\in\{1,\dots,k\}$ 
%sea $M_j=M\cap (m_1,\dots,m_j)$. El caso $k=1$ es fácil: 
%como $M_1=M\cap (m_1)\subseteq (m_1)$, existe $r_1\in R$ tal que $M_1=(r_1\cdot m_1)$. Luego $M_1=\{0\}$ o bien
%$M_1$ es libre de rango uno. 
%%Supongamos ahora que $M_j$ es libre de rango $\leq j$. Sea 
%%\[
%%I=\{r\in R:\text{ existe $m\in M$ tal que $m=\sum_{i=1}^j s_j\cdot m_j+r\cdot m_{j+1}$ para $s_1,\dots,s_j\in R$}\}.
%%\]   
%%Como $I$ es un ideal de $R$, podemos escribir $I=(r_{j+1})$, pues $R$ es un dominio de ideales principales. Si $r_{j+1}=0$, entonces
%%$M_{j+1}=M_j$ y el teorema queda demostrado. Si $r_{j+1}\ne 0$, sea $n\in M_{j+1}$ un elemento de la forma
%%\[
%%n=r_{j+1}\cdot m_{j+1}+\cdots, 
%%\]
%%donde usamos la definición del ideal $I$. Si $m\in M_{j+1}$, entonces $m=r\cdot x_{j+1}+\cdots$, donde
%%$r_{j+1}$ divide a $r$, pues como $m\in M$, entonces $r\in I=(a_{j+1})$ y luego $r=sr_{j+1}$ para algún $s\in S$. Como entonces
%%$m-s\cdot n\in M_j=M\cap (m_1,\dots,m_j)$, se concluye que
%%$M_{j+1}=M_j+(n)$. Además $M_j\cap (n)=\{0\}$, pues si $x=r\cdot y=\sum_{i=1}^j r_i\cdot m_i$, entonces
%%\[
%%(rr_{j+1})\cdot m_{j+1}+\sum_{i=1} s_i\cdot m_i=0
%%\]
%%implica que $rr_{j+1}=s_1=\cdots s_j=0$ y luego $r=0$ pues $a_{j+1}\ne 0$. 
%%\end{proof}
%%
%%El teorema anterior también vale en el caso de bases infinitas. La demostración, sin embargo, depende del lema de Zorn.
% todo: referencia al libro de lang

\begin{theorem}
	\label{thm:free+torsion}
	Let $R$ be a principal domain. 
	If $M$ is a finitely generated module, then $M=T(M)\oplus F$, where
	$F\simeq M/T(M)$ is finitely generated and free. The torsion submodule
	is unique and $F$ is unique up to isomorphism. 
\end{theorem}

\begin{proof}
	We first prove that $T(M/T(M))\simeq\{0\}$. If 
	$x+T(M)\in T(M/T(M))$, let $r\in R\setminus\{0\}$ be such that 
	$r\cdot (x+T(M))=T(M)$. Then $r\cdot x\in T(M)$, that is, there exists 
	$s\in R\setminus\{0\}$ such that $s\cdot (r\cdot x)=(sr)\cdot x=0$. 
	Since $sr\ne 0$, it follows that $x\in T(M)$. 

	Since $M$ is finitely generated, $M/T(M)$ is finitely generated. Moreover, $M/T(M)$ is torsion-free. 
	It follows that $M/T(M)$ is free. Consider the exact sequence 
	\[
		\begin{tikzcd}
			0 & T(M) & M & M/T(M) & 0
			\arrow[from=1-1, to=1-2]
			\arrow["\iota", from=1-2, to=1-3]
			\arrow["\pi", from=1-3, to=1-4]
			\arrow[from=1-4, to=1-5]
	\end{tikzcd}\]
	where $\iota$ is the inclusion map and $\pi$ is the canonical map.  Since
	$M/T(M)$ is free, there exists a module homomorphism $h\colon M/T(M)\to M$
	such that $\pi h=\id$, see Proposition \ref{pro:free=>projective}. 
	The previous lemma implies then that $M\simeq
	T(M)\oplus M/T(M)$. 	
	 
	Para demostrar la unicidad, supongamos que $M=T\oplus L$, donde $T$ es de torsión y $L$ es libre. Primero
	demostraremos que $T=T(M)$. Claramente 
	$T\subseteq T(M)$. Por otro lado, si $m\in T(M)$, entonces $m=t+l$ para ciertos $t\in T$ y $l\in L$. En particular, 
	$r\cdot m=0$ y $s\cdot t=0$ para ciertos $r,s\in R$. Como $R$ es conmutativo, 
	\[
		0=(rs)\cdot m=(rs)\cdot (t+l)=(rs)\cdot t+(rs)\cdot l=(rs)\cdot l.
	\]
	y entonces $l\in T(L)$. Pero 
	como $L$ es libre, $T(L)=\{0\}$ (pues $T(L)$ es también libre y entonces cualquier elemento $x$  
	de una base de $T(L)$ sería tal que $\{x\}$ es linealmente independiente, una contradicción). Luego 
	$l=0$ y en consecuencia $m=t\in T$. La unicidad salvo isomorfismo de la parte libre
	se obtiene inmediatamente al observar que $M/T(M)$. 
\end{proof}


%\begin{proof}
%Observemos
%que la función $R\to (m)$, $r\mapsto r\cdot m$, es un epimorfismo de módulos con núcleo
%$\Ann(m)$. Luego $R/\Ann(m)\simeq (m)$ por el primer teorema de isomorfismos. En particular,
%si $\Ann(m)=(p^\alpha)$ para algún irreducible $p\in R$, entonces 
%$(m)\simeq R/(p^\alpha)$.  
%El teorema anterior nos permite descomponer un módulo $p$-primario 
%como suma directa de módulos cíclicos. Observemos que...
%\end{proof}

\topic{Smith's normal form}

We finish the course with an algorithm that allows us to understand the
structure of certain finitely generated modules.  We will discuss the case of
modules over euclidean domains, as in this case the algorithm is constructive. 


Let $M$ be a finitely generated module and $\{m_1,\dots,m_k\}$ be a set of
generators.  There exists a surjective module homomorphism 
\[
	\varphi\colon R^k\to M, 
	\quad
	(r_1,\dots,r_k)\mapsto \sum_{i=1}^k r_i\cdot m_i,
\]
and hence 
$M\simeq R^k/\ker\varphi$. 
The submodule $\ker\varphi$ is the \textbf{relations submodule} of $M$. 
Since $R$ is an euclidean domain, $R$ is a principal domain. Since 
$M$ is finitely generated, then so is $\ker\varphi$. Let 
$\{e_1,\dots,e_l\}$ be a generating set of $\ker\varphi$, say 
\begin{align*}
e_1&=(a_{11},a_{12},\dots,a_{1k}),\\
e_2&=(a_{21},a_{22},\dots,a_{2k}),\\
&\vdots\\
e_l&=(a_{l1},a_{l2},\dots,a_{lk}).	
\end{align*}

The matrix $A=(a_{ij})_{1\leq i\leq l,1\leq j\leq k}$ is the 
\textbf{relations matrix} of $M$ with respect to $\{m_1,\dots,m_k\}$ 
and $\{e_1,\dots,e_l\}$. 

\begin{claim}
		If $P\in R^{l\times l}$ is invertible, then the rows
		$\{f_1,\dots,f_l\}$ of $PA$ generate $\ker\varphi$. Moreover, $PA$ is
		the relations matrix with respect to $\{m_1,\dots,m_k\}$ and
		$\{f_1,\dots,f_l\}$. 
\end{claim}

%Some properties:
%\begin{enumerate}
%	\item If $P\in R^{l\times l}$ is invertible, then the rows
%		$\{f_1,\dots,f_l\}$ of $PA$ generate $\ker\varphi$. Moreover, $PA$ is
%		the relations matrix with respect to $\{m_1,\dots,m_k\}$ and
%		$\{f_1,\dots,f_l\}$. 
%	\item If $Q\in R^{k\times k}$ is invertible and $Q^{-1}=(q_{ij})$ and for
%		each $j\in\{1,\dots,k\}$ we define $n_j=\sum_{i=1}^k q_{ij}\cdot m_i$,
%		the set $\{n_1,\dots,n_k\}$ generates $M$ and the rows of 
%$AQ$ generate $\ker\varphi$. Moreover, $AQ$ is the relations matrix with respect to $\{n_1\dots,n_k\}$.  
%\end{enumerate}

Let us prove the claim. Assume that $P=(p_{ij})$. The rows of $PA$ are 
%$f_1,\dots,f_l$, where 
\begin{align*}
f_1 &= p_{11}e_1+\cdots+p_{1l}e_l,\\
f_2 &= p_{21}e_1+\cdots+p_{2l}e_l,\\
&\phantom{=}\vdots\\
f_l &= p_{l1}e_1+\cdots+p_{ll}e_l.	
\end{align*}
Moreover, $f_j\in\ker\varphi$ for all $j\in\{1,\dots,l\}$. 
Since $P$ is invertible, the set $\{f_1,\dots,f_l\}$ generates $\ker\varphi$. Indeed, each 
$e_j$ is a linear combination of the $f_i$'s,  
\[
\begin{pmatrix}
e_1\\
e_2\\
\vdots\\
e_l	
\end{pmatrix}
=P^{-1}\begin{pmatrix}
f_1\\
f_2\\
\vdots\\
f_l
\end{pmatrix}.
\]
In particular, $PA$ is the relations matrix with respect to 
$\{m_1,\dots,m_k\}$ and $\{f_1,\dots,f_l\}$.  

\begin{claim}
	If $Q\in R^{k\times k}$ is invertible and $Q^{-1}=(q_{ij})$ and for each
	$j\in\{1,\dots,k\}$ we define $n_j=\sum_{i=1}^k q_{ij}\cdot m_i$, the set
	$\{n_1,\dots,n_k\}$ generates $M$ and the rows of $AQ$ generate
	$\ker\varphi$. Moreover, $AQ$ is the relations matrix with respect to
	$\{n_1\dots,n_k\}$.  
\end{claim}

Now we prove the claim. Since 
\[
\begin{pmatrix}
n_1\\
n_2\\
\vdots\\
n_k	
\end{pmatrix}
=Q^{-1}\begin{pmatrix}
m_1\\
m_2\\
\vdots\\
m_k
\end{pmatrix},
\]
it follows that 
\begin{align*} 
\begin{pmatrix}
0\\
0\\
\vdots\\
0	
\end{pmatrix}
=A\begin{pmatrix}
m_1\\
m_2\\
\vdots\\
m_k	
\end{pmatrix}
&=
(AQ)\begin{pmatrix}
	n_1\\
	n_2\\
	\vdots\\
	n_k
\end{pmatrix}.
%=(AQ)Q^{-1}\begin{pmatrix}
%	m_1\\
%	m_2\\
%	\vdots\\
%	m_k
%\end{pmatrix}
%=\begin{pmatrix}
%0\\
%0\\
%\vdots\\
%0	
%\end{pmatrix}.
\end{align*}
This implies that the rows of $AQ$ are relations with respect to the generating set 
$\{n_1,\dots,n_k\}$. 
Let $\psi\colon R^k\to M$, $(r_1,\dots,r_k)\mapsto \sum_{i=1}^k r_i\cdot n_i$.  
Let us prove that the rows of $AQ$ generate $\ker\psi$ with respect to $\{n_1,\dots,n_k\}$. 
If $(r_1,\dots,r_k)\in \ker\psi$, then 
$\sum_{i=1}^k r_i\cdot n_i=0$. Write 
\[
\begin{pmatrix}
0\\
0\\
\vdots\\
0	
\end{pmatrix}
=(r_1\cdots r_k)Q^{-1}\begin{pmatrix}
m_1\\
m_2\\
\vdots\\
m_k	
\end{pmatrix}.
\]
We remark that each $e_j$ belongs to $R^k$. Thus 
\[
(r_1\cdots r_k)Q^{-1} = \left(\sum_{i=1}^k r_i\cdot q_{i1},\sum_{i=1}^k r_i\cdot q_{2i},\dots,\sum_{i=1}^k r_i\cdot q_{ki}\right)\in \ker\varphi.
\]
Since $\ker\varphi$ is generated by $\{e_1,\dots,e_l\}$, there exist 
$s_1,\dots,s_l\in R$ such that 
\[
	(r_1\cdots r_k)Q^{-1}=\sum_{i=1}^l s_i\cdot e_i,
\]
that is 
\[
(r_1\dots r_k)Q^{-1}=(s_1\cdots s_l)\begin{pmatrix}e_1\\\vdots\\ e_l\end{pmatrix}
=(s_1\cdots s_l)\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1k}\\
\vdots & \vdots & & \vdots\\
a_{l1} & a_{l2} & \cdots & a_{lk}	
\end{pmatrix}
.
\]
Rewritting this expression as 
\[
(r_1\cdots r_k)=(s_1\cdots s_l)AQ,
\]
we conclude that  $(r_1,\dots,r_k)$ is a linear combination of the rows of $AQ$, as 
\begin{align*}
(r_1,\dots,r_k)&=\left(\sum_{i=1}^l s_i\cdot x_{i1},\dots,\sum_{i=1}^l s_i\cdot x_{ik}\right)
=\sum_{i=1}^l s_i\cdot (x_{11},\dots,x_{1k}).
\end{align*}
Therefore $\{n_1,\dots,n_k\}$ generates $M$ and the rows of $AQ$ generate the
corresponding relations submodule and $AQ$ is the relations matrix with respect
to $\{n_1,\dots,n_k\}$ and $\{e_1,\dots,e_l\}$. 

\begin{proposition}
	Let $A$ be the relations matrix of a module $M$. 
	If there exist invertible matrices $P\in R^{l\times l}$ and $Q\in R^{k\times k}$ such that 
	\[
		PAQ=
		\begin{pmatrix}
			a_1 & 0 & \cdots & \cdot & \cdot & \cdots & 0\\
			0 & a_2 & \cdots & \cdot & \cdot & \cdots & 0\\
			\vdots && \ddots &  & & & \vdots\\	
			0 & \cdot & \cdots & a_r & \cdot & \cdots & 0\\	
			0 & \cdot & \cdots & \cdot & 0 & \cdots & 0\\	
			\vdots &&&&&\ddots &\vdots\\
			0 & \cdot & \cdots & \cdot & \cdot & \cdots & 0
		\end{pmatrix}
	\]
	where $a_i\ne0$ for all $i\in\{1,\dots,r\}$ and  $a_i\mid a_{i+1}$ for all
	$i\in\{1,\dots,r-1\}$,  then 
	\[
		M\simeq R/(a_1)\oplus\cdots\oplus R/(a_r)\oplus R^{n-r}.
	\]
\end{proposition}

\begin{proof}
	The matrix $PAQ$ is the relations matrix with respect to 
	the generating set $\{m_1,\dots,m_k\}$ de $M$ and respect to the relations submodule 
	given by the rows of $PAQ$.  If $\varphi\colon R^k\to
	M$, $(r_1,\dots,r_k)\mapsto \sum_{i=1}^k r_i\cdot m_i$, then 
	$R^k/\ker\varphi\simeq M$, as $\varphi$ is a surjective homomorphism. For each 
	$j\in\{r+1,\dots,k\}$ let $a_j=0$.  Let 
	\[
		\psi\colon R^k\to R/(a_1)\oplus\cdots\oplus R/(a_k),\quad
		(s_1,\dots,s_k)\mapsto (s_1+(a_1),\dots,s_k+(a_k)). 
	\]
	A straighforward calculation shows that 
	\[
		\ker\psi=(a_1)\oplus\cdots\oplus (a_k).
	\]
	Thus 
	$R^k/\ker\psi\simeq \oplus_{i=1}^k R/(a_i)$. 
	
	It is an exercise to show that $\ker\varphi=\ker\psi$. 
	
% 	Veamos que $\ker\psi\subseteq\ker\varphi$. 
% 	Si $(s_1\cdot a_1,\dots,s_k\cdot a_k)\in (a_1)\oplus\cdots\oplus (a_k)$, entonces
% 	\[
% 	\varphi(s_1\cdot a_1,\dots,s_k\cdot a_k)=\sum_{i=1}^k s_i\cdot (a_i\cdot m_i)=0,
% 	\]
% 	pues $PAQ$ es la matriz de relaciones de $M$ con respecto a $\{m_1,\dots,m_k\}$. 
% 	Recíprocamente, si $(s_1,\dots,s_k)\in\ker\varphi, entonces
% 	\[
% 	\psi(s_1,\dots,s_k)=(r_1+(a_1),\dots,r_k+(a_k))=(0,\dots,0)
% 	\]
% 	pues $PAQ$ es la matriz de relaciones de $M$ con respecto a $\{m_1,\dots,m_k\}$. 

	Therefore $M\simeq R/(a_1)\oplus\cdots\oplus R/(a_k)$. To finish the proof
	we need to note that $R/(a_i)\simeq R$ for all $i\in\{r+1,\dots,k\}$. 
\end{proof}

The decomposition given in the previous proposition is known as 
the \textbf{Smith normal form} of the matrix $M$. 
How can we find the matrices $P$ and $Q$? 
Consider the following matrix operations: 
\begin{enumerate}
	\item Switch the $i$-th row and $j$-th row, that is $F_i\leftrightarrow F_j$.
	\item Replace row $F_i$ by $F_i+\lambda F_j$ for some $\lambda\in R$ and $j\ne i$.
	\item Switch the $i$-th column and the $j$-th column, that is $C_i\leftrightarrow C_j$.
	\item Replace column $C_i$ by $C_i+\lambda C_j$ for some $\lambda\in R$ and $j\ne i$. 
\end{enumerate}
These operations are invertible. For example, the first operation
corresponds to multiply $A$ on the left by a permutation matrix. 
a izquierda a la matriz $A$ por una matriz de permutación. The second
operation corresponds to multiply $A$ by $I+\lambda E_{ij}$ on the left, 
where 
\[
(E_{ij})_{kl}=\begin{cases}
1 & \text{if $i=k$ and $j=l$},\\
0 & \text{otherwise}.	
\end{cases}
\]
Similarly, column operations correspnd to multiply on the right the matrix $A$
either by a permutation matrix or a matrix of the form $I+\lambda E_{ij}$. 
  
\begin{theorem}[Smith's normal form]
\index{Smith's normal form}
Let $R$ be an euclidean domain. If $A\in R^{l\times k}$,  
there exists invertible matrices $P\in R^{l\times l}$ and $Q\in R^{k\times k}$ such that 
\[
PAQ=\begin{pmatrix}
a_1 & 0 & \cdots & \cdot & \cdot & \cdots & 0\\
0 & a_2 & \cdots & \cdot & \cdot & \cdots & 0\\
\vdots && \ddots &  & & & \vdots\\	
0 & \cdot & \cdots & a_r & \cdot & \cdots & 0\\	
0 & \cdot & \cdots & \cdot & 0 & \cdots & 0\\	
\vdots &&&&&\ddots &\vdots\\
0 & \cdot & \cdots & \cdot & \cdot & \cdots & 0
\end{pmatrix}
\]
where $a_1\cdots a_k\ne 0$ and $a_i\mid a_{i+1}$ for all $i\in\{1,\dots,r-1\}$.
Moreover, the elements $a_1,\dots,a_r$ are unique up to multiplication by
units. 
\end{theorem}

\begin{proof}[Sketch of the proof]
	We only prove the existence. Let $(R,\varphi)$ be an euclidean domain.  
	We need to show that $A$ can be turned into a matrix of the form 
\begin{equation*}
B=\begin{pmatrix}
	b_{11} & 0 & \cdots & 0\\
	0 & b_{22} & \cdots & b_{2m}\\
	\vdots & \vdots &&  \vdots\\
	0 & b_{n2} & \cdots & b_{nm}
\end{pmatrix}
\end{equation*}
where each  $b_{ij}$ is divisible by $b_{11}$. Then we apply the same procedure
to the submatrix 
\[
\begin{pmatrix}
	\frac{b_{22}}{b_{11}} & \cdots & \frac{b_{2m}}{b_{11}}\\
	\vdots & &\vdots \\
	\frac{b_{n2}}{b_{11}} & \cdots & \frac{b_{nm}}{b_{11}}
\end{pmatrix}
\]
and repeat the method until we cannot continue. 

Let us show how to get the matrix $B$. 
By applying row and column operations we may assume that the coefficient of $A$ 
with minimal norm appears in position
$(1,1)$.  
Si algún $a_{i1}$ no es divisible por $a_{11}$, escribimos  
$a_{i1}=a_{11}u+r$ para $u\in R$ y $r\in R$ tal que $\varphi(r)<\varphi(a_{11})$. Aplicamos entonces la transformación
$F_i\leftarrow F_i-uF_1$ y nos queda una matriz
que en el lugar $(1,i)$ tendrá al elemento $r$. Similarmente, si algún $a_{1j}$
no es divisible por $a_{11}$, entonces $a_{1j}=va_{11}+s$ con $\varphi(s)<\varphi(a_{11})$ y 
aplicamos la transformación $C_j\leftarrow C_j-vC_1$ para quedarnos con una matriz que en el lugar 
$(j,1)$ tiene al elemento $s$.  
Si todos los $a_{i1}$ son divisibles por $a_{11}$, digamos $a_{i1}=a_{11}\lambda_i$, entonces
aplicamos la transformación $F_i\leftarrow \lambda_i F_1-F_i$. Similarmente, si todos los
$a_{1j}$ son divisibles por $a_{11}$, digamos $a_{1j}=a_{11}\mu_j$, entonces aplicamos
la transformación $C_j\leftarrow \mu_j C_1-C_j$. Esto nos permite quedarnos con una matriz
de la forma
\[
\begin{pmatrix}
	a_{11} & 0\\
	0 & A_1
\end{pmatrix}
=\begin{pmatrix}
	a_{11} & 0 & \cdots & 0\\
	0 & * & \cdots & *\\
	\vdots & \vdots & \ddots & \vdots \\
	0 & * & \cdots & *
\end{pmatrix}.
\]
Si alguna de las entradas de la submatriz $A_1$ no fuera divisible por $a_{11}$, hacemos la operación
$F_1\leftarrow F_1+F_i$ o bien la operación $C_1\leftarrow C_1+C_j$ y repetimos
el procedimiento.
\end{proof}

A detailed exposition of the Smith normal form and the uniqueness can be found in\dots
Here we will explain the algorithm with examples. 

\begin{example}
Let 
\[
A=\begin{pmatrix}
	2 & 5 & 3\\
	8 & 6 & 4\\
	3 & 1 & 0
\end{pmatrix}\in\Z^{3\times3}.
\]	
Let us compute the Smith's normal form of $A$. $A$. 
Since the element with smallest norm appears in position $(3,2)$,
we apply the operations $F_1\leftrightarrow F_3$ and  $C_1\leftrightarrow C_2$ to transform $A$ into 
\[
\begin{pmatrix}
	1 & 3 & 0\\
	6 & 8 & 4\\
	5 & 2 & 3
\end{pmatrix}.
\]
Para obtener ceros en las posiciones $(1,2)$, $(1,3)$, $(2,1)$ y $(2,3)$ hacemos las operaciones
$F_2\leftrightarrow 6F_1-F_2$, $F_3\leftrightarrow 5F_1-F_3$ y luego 
$C_1\leftrightarrow 3C_1-C_2$. Nos queda entonces la matriz  
\[
\begin{pmatrix}
	1 & 3 & 0\\
	0 & -10 & -4\\
	0 & -13 & -3
\end{pmatrix}.
\]
Para sacarnos de encima los números negativos multiplicamos la segunda y la tercera fila por $-1$, que es una unidad de $\Z$:
\[
\begin{pmatrix}
	1 & 3 & 0\\
	0 & 10 & 4\\
	0 & 13 & 3
\end{pmatrix}.
\]
Ahora hacemos lo mismo en la submatriz $\begin{pmatrix}10&4\\13&3\end{pmatrix}$. Para que en el lugar $(2,2)$ nos
quede el elemento de la submatriz que tiene menor norma, aplicamos las transformaciones $F_2\leftrightarrow F_3$ y
$C_3\leftrightarrow C_2$. Nos queda entonces
\[ 
\begin{pmatrix}
3 & 13\\
4 & 10
\end{pmatrix}.
\]
Escribimos $13=3\cdot 4+1$ y aplicamos
la transformación $C_2\leftarrow C_2-4C_1$ para obtener $\begin{pmatrix}3&1\\4&-6\end{pmatrix}$. Intercambiamos 
la primera y la segunda columna y nos queda la matriz
$\begin{pmatrix}1&3\\-6&4\end{pmatrix}$. Aplicamos ahora la transformación
$F_2\leftarrow 6F_1+F_2$ y al resultado le aplicamos la transformación $C_2\leftarrow 3C_1-C_2$:
\[
\begin{pmatrix}
    1 & 0\\
    0 & 22
\end{pmatrix}.
\]
Luego
\[
\begin{pmatrix}
	1 & 0 & 0\\
	0 & 1 & 0\\
	0 & 0 & -22	
\end{pmatrix}
\]
es la forma normal de Smith de la matriz $A$.
\end{example}

Veamos ahora algunas aplicaciones.

\begin{example}
Sea $M$ el grupo abeliano con generadores $m_1,m_2,m_3$ y relaciones
$8m_1+4m_2+8m_3=0$, $4m_1+8m_2+4m_3=0$. La matriz de relaciones es entonces
\[
A=\begin{pmatrix}
8 & 4 & 8\\
4 & 8 & 4
\end{pmatrix}.
\]	
Veamos que $M\simeq\Z/4\times\Z/{12}$. Si hacemos la operación $F_1\leftarrow 2F_2-F_1$, nos queda la matriz
\[
\begin{pmatrix}
0 & 12 & 0\\
4 & 8 & 4	
\end{pmatrix},
\]
que corresponde a los generadores $\{m_1,m_2,m_3\}$ con las relaciones $12m_2=0$ y $4m_1+8m_2+4m_3=0$. Si 
hacemos simultáneamente las operaciones $C_2\leftarrow C_2-2C_1$ y $C_3\leftarrow C_3-C_1$, nos queda 
la matrix
\[
\begin{pmatrix}
0 & 12 & 0\\
4 & 0 & 0	
\end{pmatrix},
\]
que corresponde al conjunto de generadores $\{m_1+2m_2+m_3,m_2\}$ con las relaciones $12m_2=0$ y $4(m_1+2m_2+m_3)=0$. 
Por último, al intercambiar
la primera y la segunda columna, nos queda la matriz 
\[
\begin{pmatrix}
4 & 0 & 0\\
0 & 12 & 0	
\end{pmatrix},
\]
que corresponde al conjunto de generadores $\{m_2,m_1+2m_2+m_3\}$ con las relaciones $4(m_1+2m_2+m_3)=0$ y $12m_2=0$. 
En conclusión, $M\simeq\Z/4\times\Z/{12}$. 
\end{example}


\begin{example}
Sea $M$ el grupo abeliano generdo por $\{m_1,\dots,m_4\}$ y sea $K$ el subgrupo
generado por $\{e_1,e_2,e_3\}$, donde
\[
e_1=22m_3,\quad
e_2=-2m_1+2m_2-6m_3-4m_4,\quad
e_3=2m_1+2m_2+6m_3+8m_4.
\]
Queremos calcular $M/K$. 
La matriz de relaciones es 
\[
A=\begin{pmatrix}
	0 & 0 & 22 & 0\\
	-2 & 2 & -6 & -4\\
	2 & 2 & 6 & 8
\end{pmatrix}.
\]
Si aplicamos la operación $F_1\leftrightarrow F_3$ y después la operación $F_2\leftarrow F_1+F_2$ nos da la matriz
\[
\begin{pmatrix}
	2 & 2 & 6 & 8\\
	0 & 4 & 0 & 4\\
	0 & 0 & 22 & 0
\end{pmatrix}.
\]
Ahora aplicamos las operaciones $C_2\leftarrow C_2-C_1$, $C_3\leftarrow C_3-3C_1$ y $C_4\leftarrow C_4-4C_1$ y obtenemos
\[
\begin{pmatrix}
	2 & 0 & 0 & 0\\
	0 & 4 & 0 & 4\\
	0 & 0 & 22 & 0
\end{pmatrix}.
\]
Hacemos ahora $C_4\leftarrow C_4-C_2$ y nos queda la matriz
\[
\begin{pmatrix}
	2 & 0 & 0 & 0\\
	0 & 4 & 0 & 0\\
	0 & 0 & 22 & 0
\end{pmatrix}
\]
pero ahora nos encontramos con que $4\nmid 22$. Utilizamos las operaciones $F_2\leftarrow F_2+F_3$, $C_3\leftarrow C_3-5C_2$, $C_3\leftarrow C_2$, $F_3\leftarrow F_3-11F_2$ y 
$C_3\leftarrow C_3-C_2$ y nos queda
\[
\begin{pmatrix}
	2 & 0 & 0 & 0\\
	0 & 2 & 0 & 0\\
	0 & 0 & -44 & 0
\end{pmatrix}.
\]
Luego el grupo abeliano $M/K$ puede presentarse con la base $\{n_1,n_2,n_3,n_4\}$ y las relaciones
$2n_1=0$, $2n_2=0$ y $44n_3=0$. En conclusión, $M/K\simeq\Z\times (\Z/2)^2\times (\Z/44)$. 
\end{example}

\begin{example}
	Let $A=\begin{pmatrix}
		1 & -1 & 1\\
		1 & 0 & 2
	\end{pmatrix}$ and $b=\begin{pmatrix} 4 \\ 5\end{pmatrix}$. Let us solve
	the linear system $AX=b$ in the integers. We need to compute
	the Smith's normal form of $A$. For example, 
	\[
	P=\begin{pmatrix}
		0 & 1\\
		-1 & 1
	\end{pmatrix},\quad
	Q=\begin{pmatrix}
		0 & -2 & 2\\
		0 & 0 & 1\\
		0 & 1 & -1
	\end{pmatrix},
	\quad
	S=PAQ=\begin{pmatrix}
		1 & 0 & 0\\
		0 & 1 & 0
	\end{pmatrix}.
	\]
	Note that the matrix $S$ is unique, but not the 
	matrices $P$ and $Q$. To solve $AX=b$ we proceed as follows. Let 
	$Y=Q^{-1}X$. Then $AX=b$ implies that 
	\[
		SY=(PAQ)(Q^{-1}X)=Pb=\begin{pmatrix} 5 \\ 1\end{pmatrix}.
	\]	
	Write $X=\begin{pmatrix}
		x\\
		y\\
		z
	\end{pmatrix}$. Since $Q^{-1}=\begin{pmatrix}
		1 & 0 & 2\\
		0 & 1 & 1\\
		0 & 1 & 0
	\end{pmatrix}$, it follows that  
	$Y=Q^{-1}X=\begin{pmatrix}
		x+2z\\
		y+z\\
		y
	\end{pmatrix}$ and hence $SY=\begin{pmatrix}5\\1\end{pmatrix}$ turns into 
	\[
		\begin{pmatrix}
			x+2z\\
			y+z
		\end{pmatrix}
		=
	\begin{pmatrix}
		1 & 0 & 0\\
		0 & 1 & 0
	\end{pmatrix}\begin{pmatrix}
		x+2z\\
		y+z\\
		y
	\end{pmatrix}
	=\begin{pmatrix}
		5\\
		1
	\end{pmatrix}.
	\]
	It follows that the solution of $AX=b$ is then $X=\begin{pmatrix}
		x\\
		y\\
		z
	\end{pmatrix}
	=\begin{pmatrix}
		5-2z\\
		1-z\\
		z
	\end{pmatrix}$ for $z\in\Z$. 
\end{example}

\begin{exercise}
	\label{xca:AX=b}
	Solve $AX=b$ in $\Z$ for $A=\begin{pmatrix}
		0 & 1 & -1\\
		1 & -1 & 0\\
		2 & 0 & -1
	\end{pmatrix}$ and $b=\begin{pmatrix}
		5\\
		1\\
		7
	\end{pmatrix}$. 
\end{exercise}

\begin{exercise}
	\label{xca:factors_260}
	Prove that $\Z^3/\langle
	(6,6,4),(6,12,8)\rangle\simeq\Z/2\times\Z/6\times\Z$.
\end{exercise}

\begin{exercise}
	\label{xca:Smith_Z[i]}
	Compute the Smith's normal 
	form of 
	$\begin{pmatrix}
		1+i & 2-i\\
		3 & 5i
	\end{pmatrix}\in M_2(\Z[i])$. 
\end{exercise}

\begin{exercise}
	\label{xca:Smith_Q[X]}
	Compute the Smith's normal form of
	\[
		\begin{pmatrix}
			7 & X & 0 & -X \\
			0 & X-3 & 0 & 3\\
			0 & 0 & X-4 & 0 \\
			X-6 & -1 & 0 & X+1 
		\end{pmatrix}\in\Q[X].
	\]
\end{exercise}
